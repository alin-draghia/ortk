{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import make_regression\n",
      "import matplotlib.pyplot as plt\n",
      "X, y, c = make_regression(n_samples=30, n_features=1, n_informative=1,coef=True, noise=6.0, bias=-3)\n",
      "\n",
      "ax = plt.gca()\n",
      "plt.title('Regresie')\n",
      "pts = ax.scatter(X,y, c='red', label=r'${ \\mathcal{D} = \\{(x_i,y_i)|x_i \\in X, y_i \\in Y\\}|_{i=1}^n }$')\n",
      "line, = ax.plot(X, X*c, c='green', label=r'${f(x)\\approx y}$')\n",
      "plt.xlabel('x')\n",
      "plt.ylabel('y')\n",
      "ax.legend(loc='upper left')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import make_classification\n",
      "from sklearn.linear_model import Perceptron\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, n_repeated=0, n_clusters_per_class=1, \n",
      "                           class_sep=1.5)\n",
      "#np.random.seed(0)\n",
      "#X = np.r_[0.1 * np.random.randn(30, 2) - [2, 2], 0.1 * np.random.randn(30, 2) + [2, 2]]\n",
      "#y = np.r_[[0] * 30 + [1] * 30]\n",
      "\n",
      "plt.title('Clasificare')\n",
      "X0 = X[:,0].ravel()\n",
      "X1 = X[:,1].ravel()\n",
      "plt.scatter(X0[y==0], X1[y==0], s=50, c='red', label='pozitive')\n",
      "plt.scatter(X0[y==1], X1[y==1], s=50, c='green', label='negative')\n",
      "#plt.scatter(X0, X1, s=50, c=y)\n",
      "\n",
      "classifier = Perceptron(verbose=9, shuffle=True, n_iter=500, alpha=)\n",
      "classifier.fit(X,y)\n",
      "\n",
      "w = classifier.coef_.ravel()\n",
      "b = classifier.intercept_\n",
      "\n",
      "xf = np.linspace(-4,4)\n",
      "yf = xf * w[0] + xf * w[1] + b\n",
      "\n",
      "plt.plot(xf,yf, label=r'${f(x)\\approx y}$')\n",
      "ax = plt.gca()\n",
      "ax.legend(loc='upper left')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-- Epoch 1\n",
        "Norm: 6.40, NNZs: 2, Bias: 2.000000, T: 100, Avg. loss: 0.109267\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 2\n",
        "Norm: 5.06, NNZs: 2, Bias: 3.000000, T: 200, Avg. loss: 0.098521\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 3\n",
        "Norm: 6.71, NNZs: 2, Bias: 2.000000, T: 300, Avg. loss: 0.091149\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 4\n",
        "Norm: 5.84, NNZs: 2, Bias: 3.000000, T: 400, Avg. loss: 0.103127\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 5\n",
        "Norm: 6.17, NNZs: 2, Bias: 3.000000, T: 500, Avg. loss: 0.104279\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 6\n",
        "Norm: 6.22, NNZs: 2, Bias: 4.000000, T: 600, Avg. loss: 0.102229\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 7\n",
        "Norm: 6.19, NNZs: 2, Bias: 4.000000, T: 700, Avg. loss: 0.098419\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 8\n",
        "Norm: 6.32, NNZs: 2, Bias: 3.000000, T: 800, Avg. loss: 0.093861\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 9\n",
        "Norm: 7.05, NNZs: 2, Bias: 3.000000, T: 900, Avg. loss: 0.094557\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 10\n",
        "Norm: 6.64, NNZs: 2, Bias: 4.000000, T: 1000, Avg. loss: 0.094022\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 11\n",
        "Norm: 6.62, NNZs: 2, Bias: 3.000000, T: 1100, Avg. loss: 0.094427\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 12\n",
        "Norm: 5.88, NNZs: 2, Bias: 4.000000, T: 1200, Avg. loss: 0.095877\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 13\n",
        "Norm: 6.03, NNZs: 2, Bias: 3.000000, T: 1300, Avg. loss: 0.095177\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 14\n",
        "Norm: 6.85, NNZs: 2, Bias: 4.000000, T: 1400, Avg. loss: 0.094220\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 15\n",
        "Norm: 5.64, NNZs: 2, Bias: 5.000000, T: 1500, Avg. loss: 0.091937\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 16\n",
        "Norm: 6.70, NNZs: 2, Bias: 3.000000, T: 1600, Avg. loss: 0.094246\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 17\n",
        "Norm: 6.35, NNZs: 2, Bias: 4.000000, T: 1700, Avg. loss: 0.094184\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 18\n",
        "Norm: 6.22, NNZs: 2, Bias: 4.000000, T: 1800, Avg. loss: 0.093717\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 19\n",
        "Norm: 6.76, NNZs: 2, Bias: 3.000000, T: 1900, Avg. loss: 0.095369\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 20\n",
        "Norm: 6.51, NNZs: 2, Bias: 3.000000, T: 2000, Avg. loss: 0.097215\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 21\n",
        "Norm: 6.69, NNZs: 2, Bias: 3.000000, T: 2100, Avg. loss: 0.096053\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 22\n",
        "Norm: 6.39, NNZs: 2, Bias: 4.000000, T: 2200, Avg. loss: 0.094588\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 23\n",
        "Norm: 6.25, NNZs: 2, Bias: 3.000000, T: 2300, Avg. loss: 0.094716\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 24\n",
        "Norm: 5.73, NNZs: 2, Bias: 3.000000, T: 2400, Avg. loss: 0.093665\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 25\n",
        "Norm: 6.96, NNZs: 2, Bias: 3.000000, T: 2500, Avg. loss: 0.092836\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 26\n",
        "Norm: 6.10, NNZs: 2, Bias: 4.000000, T: 2600, Avg. loss: 0.093370\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 27\n",
        "Norm: 5.95, NNZs: 2, Bias: 4.000000, T: 2700, Avg. loss: 0.093667\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 28\n",
        "Norm: 5.19, NNZs: 2, Bias: 4.000000, T: 2800, Avg. loss: 0.093688\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 29\n",
        "Norm: 5.60, NNZs: 2, Bias: 3.000000, T: 2900, Avg. loss: 0.092981\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 30\n",
        "Norm: 5.90, NNZs: 2, Bias: 4.000000, T: 3000, Avg. loss: 0.092149\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 31\n",
        "Norm: 6.95, NNZs: 2, Bias: 3.000000, T: 3100, Avg. loss: 0.091682\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 32\n",
        "Norm: 7.13, NNZs: 2, Bias: 3.000000, T: 3200, Avg. loss: 0.092251\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 33\n",
        "Norm: 7.95, NNZs: 2, Bias: 3.000000, T: 3300, Avg. loss: 0.092734\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 34\n",
        "Norm: 8.55, NNZs: 2, Bias: 4.000000, T: 3400, Avg. loss: 0.091817\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 35\n",
        "Norm: 8.45, NNZs: 2, Bias: 4.000000, T: 3500, Avg. loss: 0.092823\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 36\n",
        "Norm: 7.64, NNZs: 2, Bias: 4.000000, T: 3600, Avg. loss: 0.093291\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 37\n",
        "Norm: 7.26, NNZs: 2, Bias: 4.000000, T: 3700, Avg. loss: 0.094675\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 38\n",
        "Norm: 7.01, NNZs: 2, Bias: 4.000000, T: 3800, Avg. loss: 0.094008\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 39\n",
        "Norm: 7.31, NNZs: 2, Bias: 3.000000, T: 3900, Avg. loss: 0.093260\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 40\n",
        "Norm: 6.47, NNZs: 2, Bias: 4.000000, T: 4000, Avg. loss: 0.093645\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 41\n",
        "Norm: 7.00, NNZs: 2, Bias: 4.000000, T: 4100, Avg. loss: 0.093739\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 42\n",
        "Norm: 6.93, NNZs: 2, Bias: 3.000000, T: 4200, Avg. loss: 0.093732\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 43\n",
        "Norm: 7.38, NNZs: 2, Bias: 4.000000, T: 4300, Avg. loss: 0.092910\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 44\n",
        "Norm: 8.03, NNZs: 2, Bias: 4.000000, T: 4400, Avg. loss: 0.093190\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 45\n",
        "Norm: 8.71, NNZs: 2, Bias: 4.000000, T: 4500, Avg. loss: 0.093164\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 46\n",
        "Norm: 7.84, NNZs: 2, Bias: 6.000000, T: 4600, Avg. loss: 0.093642\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 47\n",
        "Norm: 7.97, NNZs: 2, Bias: 5.000000, T: 4700, Avg. loss: 0.093976\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 48\n",
        "Norm: 8.23, NNZs: 2, Bias: 4.000000, T: 4800, Avg. loss: 0.093182\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 49\n",
        "Norm: 7.03, NNZs: 2, Bias: 5.000000, T: 4900, Avg. loss: 0.094337\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 50\n",
        "Norm: 7.82, NNZs: 2, Bias: 4.000000, T: 5000, Avg. loss: 0.094809\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 51\n",
        "Norm: 7.47, NNZs: 2, Bias: 5.000000, T: 5100, Avg. loss: 0.094611\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 52\n",
        "Norm: 8.16, NNZs: 2, Bias: 4.000000, T: 5200, Avg. loss: 0.095154\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 53\n",
        "Norm: 6.88, NNZs: 2, Bias: 5.000000, T: 5300, Avg. loss: 0.095053\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 54\n",
        "Norm: 7.56, NNZs: 2, Bias: 4.000000, T: 5400, Avg. loss: 0.094447\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 55\n",
        "Norm: 7.93, NNZs: 2, Bias: 4.000000, T: 5500, Avg. loss: 0.094759\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 56\n",
        "Norm: 8.10, NNZs: 2, Bias: 3.000000, T: 5600, Avg. loss: 0.095246\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 57\n",
        "Norm: 7.32, NNZs: 2, Bias: 4.000000, T: 5700, Avg. loss: 0.095830\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 58\n",
        "Norm: 6.95, NNZs: 2, Bias: 3.000000, T: 5800, Avg. loss: 0.096236\n",
        "Total training time: 0.00 seconds.\n",
        "-- Epoch 59\n",
        "Norm: 6.43, NNZs: 2, Bias: 3.000000, T: 5900, Avg. loss: 0.095843\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 60\n",
        "Norm: 5.91, NNZs: 2, Bias: 3.000000, T: 6000, Avg. loss: 0.095416\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 61\n",
        "Norm: 6.62, NNZs: 2, Bias: 5.000000, T: 6100, Avg. loss: 0.094798\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 62\n",
        "Norm: 6.23, NNZs: 2, Bias: 4.000000, T: 6200, Avg. loss: 0.095263\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 63\n",
        "Norm: 7.42, NNZs: 2, Bias: 3.000000, T: 6300, Avg. loss: 0.095412\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 64\n",
        "Norm: 6.89, NNZs: 2, Bias: 3.000000, T: 6400, Avg. loss: 0.095103\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 65\n",
        "Norm: 6.86, NNZs: 2, Bias: 4.000000, T: 6500, Avg. loss: 0.095141\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 66\n",
        "Norm: 7.02, NNZs: 2, Bias: 5.000000, T: 6600, Avg. loss: 0.095006\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 67\n",
        "Norm: 6.78, NNZs: 2, Bias: 5.000000, T: 6700, Avg. loss: 0.095562\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 68\n",
        "Norm: 7.30, NNZs: 2, Bias: 4.000000, T: 6800, Avg. loss: 0.095440\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 69\n",
        "Norm: 7.58, NNZs: 2, Bias: 4.000000, T: 6900, Avg. loss: 0.094808\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 70\n",
        "Norm: 6.71, NNZs: 2, Bias: 4.000000, T: 7000, Avg. loss: 0.094989\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 71\n",
        "Norm: 5.83, NNZs: 2, Bias: 5.000000, T: 7100, Avg. loss: 0.094668\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 72\n",
        "Norm: 5.23, NNZs: 2, Bias: 5.000000, T: 7200, Avg. loss: 0.094078\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 73\n",
        "Norm: 6.63, NNZs: 2, Bias: 4.000000, T: 7300, Avg. loss: 0.094066\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 74\n",
        "Norm: 7.41, NNZs: 2, Bias: 3.000000, T: 7400, Avg. loss: 0.094805\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 75\n",
        "Norm: 6.72, NNZs: 2, Bias: 4.000000, T: 7500, Avg. loss: 0.094860\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 76\n",
        "Norm: 5.90, NNZs: 2, Bias: 4.000000, T: 7600, Avg. loss: 0.094883\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 77\n",
        "Norm: 6.35, NNZs: 2, Bias: 3.000000, T: 7700, Avg. loss: 0.094530\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 78\n",
        "Norm: 6.88, NNZs: 2, Bias: 4.000000, T: 7800, Avg. loss: 0.094357\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 79\n",
        "Norm: 7.46, NNZs: 2, Bias: 2.000000, T: 7900, Avg. loss: 0.094247\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 80\n",
        "Norm: 7.98, NNZs: 2, Bias: 3.000000, T: 8000, Avg. loss: 0.094206\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 81\n",
        "Norm: 7.18, NNZs: 2, Bias: 4.000000, T: 8100, Avg. loss: 0.094633\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 82\n",
        "Norm: 6.85, NNZs: 2, Bias: 3.000000, T: 8200, Avg. loss: 0.094897\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 83\n",
        "Norm: 5.75, NNZs: 2, Bias: 4.000000, T: 8300, Avg. loss: 0.095410\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 84\n",
        "Norm: 5.15, NNZs: 2, Bias: 5.000000, T: 8400, Avg. loss: 0.095141\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 85\n",
        "Norm: 6.84, NNZs: 2, Bias: 3.000000, T: 8500, Avg. loss: 0.094388\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 86\n",
        "Norm: 7.48, NNZs: 2, Bias: 3.000000, T: 8600, Avg. loss: 0.094529\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 87\n",
        "Norm: 6.28, NNZs: 2, Bias: 4.000000, T: 8700, Avg. loss: 0.095173\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 88\n",
        "Norm: 6.48, NNZs: 2, Bias: 4.000000, T: 8800, Avg. loss: 0.095346\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 89\n",
        "Norm: 7.36, NNZs: 2, Bias: 2.000000, T: 8900, Avg. loss: 0.094762\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 90\n",
        "Norm: 6.95, NNZs: 2, Bias: 4.000000, T: 9000, Avg. loss: 0.094713\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 91\n",
        "Norm: 6.89, NNZs: 2, Bias: 3.000000, T: 9100, Avg. loss: 0.094767\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 92\n",
        "Norm: 6.74, NNZs: 2, Bias: 3.000000, T: 9200, Avg. loss: 0.094292\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 93\n",
        "Norm: 8.81, NNZs: 2, Bias: 4.000000, T: 9300, Avg. loss: 0.094189\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 94\n",
        "Norm: 9.32, NNZs: 2, Bias: 4.000000, T: 9400, Avg. loss: 0.094227\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 95\n",
        "Norm: 8.74, NNZs: 2, Bias: 4.000000, T: 9500, Avg. loss: 0.094233\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 96\n",
        "Norm: 7.84, NNZs: 2, Bias: 5.000000, T: 9600, Avg. loss: 0.094705\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 97\n",
        "Norm: 7.94, NNZs: 2, Bias: 4.000000, T: 9700, Avg. loss: 0.094489\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 98\n",
        "Norm: 7.58, NNZs: 2, Bias: 4.000000, T: 9800, Avg. loss: 0.094995\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 99\n",
        "Norm: 7.96, NNZs: 2, Bias: 4.000000, T: 9900, Avg. loss: 0.095033\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 100\n",
        "Norm: 7.70, NNZs: 2, Bias: 5.000000, T: 10000, Avg. loss: 0.095084\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 101\n",
        "Norm: 7.50, NNZs: 2, Bias: 5.000000, T: 10100, Avg. loss: 0.094987\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 102\n",
        "Norm: 8.66, NNZs: 2, Bias: 4.000000, T: 10200, Avg. loss: 0.095088\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 103\n",
        "Norm: 7.39, NNZs: 2, Bias: 5.000000, T: 10300, Avg. loss: 0.095711\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 104\n",
        "Norm: 7.21, NNZs: 2, Bias: 5.000000, T: 10400, Avg. loss: 0.095806\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 105\n",
        "Norm: 7.21, NNZs: 2, Bias: 4.000000, T: 10500, Avg. loss: 0.095851\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 106\n",
        "Norm: 6.53, NNZs: 2, Bias: 5.000000, T: 10600, Avg. loss: 0.095913\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 107\n",
        "Norm: 7.15, NNZs: 2, Bias: 3.000000, T: 10700, Avg. loss: 0.095996\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 108\n",
        "Norm: 8.28, NNZs: 2, Bias: 4.000000, T: 10800, Avg. loss: 0.095486\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 109\n",
        "Norm: 7.02, NNZs: 2, Bias: 5.000000, T: 10900, Avg. loss: 0.095350\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 110\n",
        "Norm: 7.42, NNZs: 2, Bias: 4.000000, T: 11000, Avg. loss: 0.095766\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 111\n",
        "Norm: 6.60, NNZs: 2, Bias: 5.000000, T: 11100, Avg. loss: 0.095940\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 112\n",
        "Norm: 6.54, NNZs: 2, Bias: 5.000000, T: 11200, Avg. loss: 0.095811\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 113\n",
        "Norm: 7.75, NNZs: 2, Bias: 3.000000, T: 11300, Avg. loss: 0.095453\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 114\n",
        "Norm: 6.56, NNZs: 2, Bias: 4.000000, T: 11400, Avg. loss: 0.095313\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 115\n",
        "Norm: 7.47, NNZs: 2, Bias: 4.000000, T: 11500, Avg. loss: 0.095264\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 116\n",
        "Norm: 7.68, NNZs: 2, Bias: 4.000000, T: 11600, Avg. loss: 0.095118\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 117\n",
        "Norm: 7.58, NNZs: 2, Bias: 3.000000, T: 11700, Avg. loss: 0.095133\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 118\n",
        "Norm: 6.87, NNZs: 2, Bias: 4.000000, T: 11800, Avg. loss: 0.095317\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 119\n",
        "Norm: 7.11, NNZs: 2, Bias: 4.000000, T: 11900, Avg. loss: 0.094906\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 120\n",
        "Norm: 6.29, NNZs: 2, Bias: 5.000000, T: 12000, Avg. loss: 0.094773\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 121\n",
        "Norm: 7.05, NNZs: 2, Bias: 5.000000, T: 12100, Avg. loss: 0.094484\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 122\n",
        "Norm: 6.31, NNZs: 2, Bias: 5.000000, T: 12200, Avg. loss: 0.094544\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 123\n",
        "Norm: 6.73, NNZs: 2, Bias: 4.000000, T: 12300, Avg. loss: 0.094403\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 124\n",
        "Norm: 6.02, NNZs: 2, Bias: 5.000000, T: 12400, Avg. loss: 0.094335\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 125\n",
        "Norm: 7.01, NNZs: 2, Bias: 3.000000, T: 12500, Avg. loss: 0.094074\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 126\n",
        "Norm: 6.23, NNZs: 2, Bias: 4.000000, T: 12600, Avg. loss: 0.094139\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 127\n",
        "Norm: 7.19, NNZs: 2, Bias: 3.000000, T: 12700, Avg. loss: 0.094338\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 128\n",
        "Norm: 7.96, NNZs: 2, Bias: 3.000000, T: 12800, Avg. loss: 0.094196\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 129\n",
        "Norm: 7.63, NNZs: 2, Bias: 3.000000, T: 12900, Avg. loss: 0.094569\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 130\n",
        "Norm: 6.93, NNZs: 2, Bias: 3.000000, T: 13000, Avg. loss: 0.094577\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 131\n",
        "Norm: 7.26, NNZs: 2, Bias: 3.000000, T: 13100, Avg. loss: 0.094775\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 132\n",
        "Norm: 6.35, NNZs: 2, Bias: 4.000000, T: 13200, Avg. loss: 0.094728\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 133\n",
        "Norm: 6.62, NNZs: 2, Bias: 3.000000, T: 13300, Avg. loss: 0.094388\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 134\n",
        "Norm: 6.68, NNZs: 2, Bias: 3.000000, T: 13400, Avg. loss: 0.094362\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 135\n",
        "Norm: 6.44, NNZs: 2, Bias: 3.000000, T: 13500, Avg. loss: 0.094608\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 136\n",
        "Norm: 5.54, NNZs: 2, Bias: 3.000000, T: 13600, Avg. loss: 0.094639\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 137\n",
        "Norm: 6.83, NNZs: 2, Bias: 3.000000, T: 13700, Avg. loss: 0.094235\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 138\n",
        "Norm: 7.54, NNZs: 2, Bias: 3.000000, T: 13800, Avg. loss: 0.094309\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 139\n",
        "Norm: 7.81, NNZs: 2, Bias: 4.000000, T: 13900, Avg. loss: 0.094342\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 140\n",
        "Norm: 6.61, NNZs: 2, Bias: 6.000000, T: 14000, Avg. loss: 0.094197\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 141\n",
        "Norm: 7.37, NNZs: 2, Bias: 4.000000, T: 14100, Avg. loss: 0.094318\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 142\n",
        "Norm: 7.59, NNZs: 2, Bias: 3.000000, T: 14200, Avg. loss: 0.094016\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 143\n",
        "Norm: 7.58, NNZs: 2, Bias: 4.000000, T: 14300, Avg. loss: 0.094034\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 144\n",
        "Norm: 7.81, NNZs: 2, Bias: 4.000000, T: 14400, Avg. loss: 0.094063\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 145\n",
        "Norm: 6.81, NNZs: 2, Bias: 5.000000, T: 14500, Avg. loss: 0.094319\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 146\n",
        "Norm: 7.46, NNZs: 2, Bias: 4.000000, T: 14600, Avg. loss: 0.094530\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 147\n",
        "Norm: 6.06, NNZs: 2, Bias: 5.000000, T: 14700, Avg. loss: 0.094486\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 148\n",
        "Norm: 6.71, NNZs: 2, Bias: 4.000000, T: 14800, Avg. loss: 0.094470\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 149\n",
        "Norm: 6.52, NNZs: 2, Bias: 4.000000, T: 14900, Avg. loss: 0.094394\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 150\n",
        "Norm: 6.93, NNZs: 2, Bias: 3.000000, T: 15000, Avg. loss: 0.094187\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 151\n",
        "Norm: 7.28, NNZs: 2, Bias: 3.000000, T: 15100, Avg. loss: 0.094353\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 152\n",
        "Norm: 6.55, NNZs: 2, Bias: 4.000000, T: 15200, Avg. loss: 0.094394\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 153\n",
        "Norm: 6.49, NNZs: 2, Bias: 3.000000, T: 15300, Avg. loss: 0.094384\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 154\n",
        "Norm: 5.97, NNZs: 2, Bias: 3.000000, T: 15400, Avg. loss: 0.094230\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 155\n",
        "Norm: 4.95, NNZs: 2, Bias: 5.000000, T: 15500, Avg. loss: 0.093916\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 156\n",
        "Norm: 6.23, NNZs: 2, Bias: 3.000000, T: 15600, Avg. loss: 0.093813\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 157\n",
        "Norm: 7.12, NNZs: 2, Bias: 4.000000, T: 15700, Avg. loss: 0.093667\n",
        "Total training time: 0.01 seconds.\n",
        "-- Epoch 158\n",
        "Norm: 6.88, NNZs: 2, Bias: 4.000000, T: 15800, Avg. loss: 0.093508\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 159\n",
        "Norm: 6.30, NNZs: 2, Bias: 5.000000, T: 15900, Avg. loss: 0.093507\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 160\n",
        "Norm: 7.38, NNZs: 2, Bias: 3.000000, T: 16000, Avg. loss: 0.093207\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 161\n",
        "Norm: 6.69, NNZs: 2, Bias: 4.000000, T: 16100, Avg. loss: 0.093243\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 162\n",
        "Norm: 7.42, NNZs: 2, Bias: 3.000000, T: 16200, Avg. loss: 0.093228\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 163\n",
        "Norm: 7.13, NNZs: 2, Bias: 4.000000, T: 16300, Avg. loss: 0.093189\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 164\n",
        "Norm: 6.95, NNZs: 2, Bias: 4.000000, T: 16400, Avg. loss: 0.093216\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 165\n",
        "Norm: 5.97, NNZs: 2, Bias: 5.000000, T: 16500, Avg. loss: 0.093384\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 166\n",
        "Norm: 5.34, NNZs: 2, Bias: 5.000000, T: 16600, Avg. loss: 0.093292\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 167\n",
        "Norm: 5.99, NNZs: 2, Bias: 5.000000, T: 16700, Avg. loss: 0.093248\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 168\n",
        "Norm: 6.22, NNZs: 2, Bias: 3.000000, T: 16800, Avg. loss: 0.093484\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 169\n",
        "Norm: 5.68, NNZs: 2, Bias: 3.000000, T: 16900, Avg. loss: 0.093287\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 170\n",
        "Norm: 5.06, NNZs: 2, Bias: 4.000000, T: 17000, Avg. loss: 0.093361\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 171\n",
        "Norm: 7.71, NNZs: 2, Bias: 3.000000, T: 17100, Avg. loss: 0.093349\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 172\n",
        "Norm: 7.19, NNZs: 2, Bias: 3.000000, T: 17200, Avg. loss: 0.093255\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 173\n",
        "Norm: 7.23, NNZs: 2, Bias: 2.000000, T: 17300, Avg. loss: 0.093155\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 174\n",
        "Norm: 7.77, NNZs: 2, Bias: 3.000000, T: 17400, Avg. loss: 0.093141\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 175\n",
        "Norm: 6.93, NNZs: 2, Bias: 4.000000, T: 17500, Avg. loss: 0.093349\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 176\n",
        "Norm: 6.69, NNZs: 2, Bias: 3.000000, T: 17600, Avg. loss: 0.093445\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 177\n",
        "Norm: 5.85, NNZs: 2, Bias: 4.000000, T: 17700, Avg. loss: 0.093498\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 178\n",
        "Norm: 5.89, NNZs: 2, Bias: 5.000000, T: 17800, Avg. loss: 0.093440\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 179\n",
        "Norm: 7.72, NNZs: 2, Bias: 3.000000, T: 17900, Avg. loss: 0.093188\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 180\n",
        "Norm: 7.31, NNZs: 2, Bias: 3.000000, T: 18000, Avg. loss: 0.093487\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 181\n",
        "Norm: 6.11, NNZs: 2, Bias: 4.000000, T: 18100, Avg. loss: 0.093792\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 182\n",
        "Norm: 6.31, NNZs: 2, Bias: 4.000000, T: 18200, Avg. loss: 0.093886\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 183\n",
        "Norm: 7.19, NNZs: 2, Bias: 2.000000, T: 18300, Avg. loss: 0.093617\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 184\n",
        "Norm: 6.78, NNZs: 2, Bias: 4.000000, T: 18400, Avg. loss: 0.093595\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 185\n",
        "Norm: 6.72, NNZs: 2, Bias: 3.000000, T: 18500, Avg. loss: 0.093628\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 186\n",
        "Norm: 6.57, NNZs: 2, Bias: 3.000000, T: 18600, Avg. loss: 0.093398\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 187\n",
        "Norm: 6.53, NNZs: 2, Bias: 4.000000, T: 18700, Avg. loss: 0.093428\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 188\n",
        "Norm: 8.29, NNZs: 2, Bias: 3.000000, T: 18800, Avg. loss: 0.093359\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 189\n",
        "Norm: 7.29, NNZs: 2, Bias: 4.000000, T: 18900, Avg. loss: 0.093285\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 190\n",
        "Norm: 7.06, NNZs: 2, Bias: 4.000000, T: 19000, Avg. loss: 0.093503\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 191\n",
        "Norm: 7.75, NNZs: 2, Bias: 4.000000, T: 19100, Avg. loss: 0.093470\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 192\n",
        "Norm: 7.39, NNZs: 2, Bias: 4.000000, T: 19200, Avg. loss: 0.093729\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 193\n",
        "Norm: 7.77, NNZs: 2, Bias: 4.000000, T: 19300, Avg. loss: 0.093761\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 194\n",
        "Norm: 7.51, NNZs: 2, Bias: 5.000000, T: 19400, Avg. loss: 0.093790\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 195\n",
        "Norm: 7.60, NNZs: 2, Bias: 5.000000, T: 19500, Avg. loss: 0.093624\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 196\n",
        "Norm: 8.67, NNZs: 2, Bias: 4.000000, T: 19600, Avg. loss: 0.093714\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 197\n",
        "Norm: 7.47, NNZs: 2, Bias: 5.000000, T: 19700, Avg. loss: 0.094025\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 198\n",
        "Norm: 8.37, NNZs: 2, Bias: 4.000000, T: 19800, Avg. loss: 0.093961\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 199\n",
        "Norm: 7.91, NNZs: 2, Bias: 5.000000, T: 19900, Avg. loss: 0.093869\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 200\n",
        "Norm: 7.61, NNZs: 2, Bias: 5.000000, T: 20000, Avg. loss: 0.094101\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 201\n",
        "Norm: 7.68, NNZs: 2, Bias: 4.000000, T: 20100, Avg. loss: 0.094118\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 202\n",
        "Norm: 6.84, NNZs: 2, Bias: 5.000000, T: 20200, Avg. loss: 0.094113\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 203\n",
        "Norm: 7.01, NNZs: 2, Bias: 4.000000, T: 20300, Avg. loss: 0.094110\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 204\n",
        "Norm: 6.95, NNZs: 2, Bias: 4.000000, T: 20400, Avg. loss: 0.094206\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 205\n",
        "Norm: 6.29, NNZs: 2, Bias: 5.000000, T: 20500, Avg. loss: 0.094240\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 206\n",
        "Norm: 6.10, NNZs: 2, Bias: 4.000000, T: 20600, Avg. loss: 0.094354\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 207\n",
        "Norm: 6.87, NNZs: 2, Bias: 3.000000, T: 20700, Avg. loss: 0.094415\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 208\n",
        "Norm: 5.98, NNZs: 2, Bias: 3.000000, T: 20800, Avg. loss: 0.094454\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 209\n",
        "Norm: 7.01, NNZs: 2, Bias: 3.000000, T: 20900, Avg. loss: 0.094505\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 210\n",
        "Norm: 6.37, NNZs: 2, Bias: 4.000000, T: 21000, Avg. loss: 0.094500\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 211\n",
        "Norm: 6.17, NNZs: 2, Bias: 3.000000, T: 21100, Avg. loss: 0.094531\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 212\n",
        "Norm: 6.07, NNZs: 2, Bias: 3.000000, T: 21200, Avg. loss: 0.094672\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 213\n",
        "Norm: 5.78, NNZs: 2, Bias: 3.000000, T: 21300, Avg. loss: 0.094538\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 214\n",
        "Norm: 5.12, NNZs: 2, Bias: 4.000000, T: 21400, Avg. loss: 0.094510\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 215\n",
        "Norm: 6.02, NNZs: 2, Bias: 2.000000, T: 21500, Avg. loss: 0.094308\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 216\n",
        "Norm: 5.14, NNZs: 2, Bias: 3.000000, T: 21600, Avg. loss: 0.094458\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 217\n",
        "Norm: 5.72, NNZs: 2, Bias: 2.000000, T: 21700, Avg. loss: 0.094245\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 218\n",
        "Norm: 4.48, NNZs: 2, Bias: 3.000000, T: 21800, Avg. loss: 0.094122\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 219\n",
        "Norm: 5.03, NNZs: 2, Bias: 2.000000, T: 21900, Avg. loss: 0.093828\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 220\n",
        "Norm: 5.55, NNZs: 2, Bias: 2.000000, T: 22000, Avg. loss: 0.093752\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 221\n",
        "Norm: 6.12, NNZs: 2, Bias: 3.000000, T: 22100, Avg. loss: 0.093682\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 222\n",
        "Norm: 7.39, NNZs: 2, Bias: 3.000000, T: 22200, Avg. loss: 0.093593\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 223\n",
        "Norm: 7.28, NNZs: 2, Bias: 3.000000, T: 22300, Avg. loss: 0.093742\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 224\n",
        "Norm: 6.52, NNZs: 2, Bias: 3.000000, T: 22400, Avg. loss: 0.093758\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 225\n",
        "Norm: 6.88, NNZs: 2, Bias: 3.000000, T: 22500, Avg. loss: 0.093872\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 226\n",
        "Norm: 6.69, NNZs: 2, Bias: 3.000000, T: 22600, Avg. loss: 0.093826\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 227\n",
        "Norm: 6.31, NNZs: 2, Bias: 3.000000, T: 22700, Avg. loss: 0.093709\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 228\n",
        "Norm: 6.35, NNZs: 2, Bias: 3.000000, T: 22800, Avg. loss: 0.093702\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 229\n",
        "Norm: 6.09, NNZs: 2, Bias: 3.000000, T: 22900, Avg. loss: 0.093851\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 230\n",
        "Norm: 5.21, NNZs: 2, Bias: 3.000000, T: 23000, Avg. loss: 0.093855\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 231\n",
        "Norm: 6.50, NNZs: 2, Bias: 3.000000, T: 23100, Avg. loss: 0.093638\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 232\n",
        "Norm: 7.23, NNZs: 2, Bias: 3.000000, T: 23200, Avg. loss: 0.093688\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 233\n",
        "Norm: 7.48, NNZs: 2, Bias: 4.000000, T: 23300, Avg. loss: 0.093720\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 234\n",
        "Norm: 6.69, NNZs: 2, Bias: 5.000000, T: 23400, Avg. loss: 0.093732\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 235\n",
        "Norm: 6.85, NNZs: 2, Bias: 5.000000, T: 23500, Avg. loss: 0.093606\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 236\n",
        "Norm: 7.73, NNZs: 2, Bias: 4.000000, T: 23600, Avg. loss: 0.093393\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 237\n",
        "Norm: 7.51, NNZs: 2, Bias: 5.000000, T: 23700, Avg. loss: 0.093443\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 238\n",
        "Norm: 8.42, NNZs: 2, Bias: 4.000000, T: 23800, Avg. loss: 0.093461\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 239\n",
        "Norm: 7.42, NNZs: 2, Bias: 5.000000, T: 23900, Avg. loss: 0.093641\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 240\n",
        "Norm: 8.12, NNZs: 2, Bias: 4.000000, T: 24000, Avg. loss: 0.093763\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 241\n",
        "Norm: 6.85, NNZs: 2, Bias: 5.000000, T: 24100, Avg. loss: 0.093742\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 242\n",
        "Norm: 7.53, NNZs: 2, Bias: 4.000000, T: 24200, Avg. loss: 0.093613\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 243\n",
        "Norm: 7.90, NNZs: 2, Bias: 4.000000, T: 24300, Avg. loss: 0.093686\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 244\n",
        "Norm: 8.06, NNZs: 2, Bias: 3.000000, T: 24400, Avg. loss: 0.093807\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 245\n",
        "Norm: 7.27, NNZs: 2, Bias: 4.000000, T: 24500, Avg. loss: 0.093950\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 246\n",
        "Norm: 6.92, NNZs: 2, Bias: 3.000000, T: 24600, Avg. loss: 0.094048\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 247\n",
        "Norm: 6.40, NNZs: 2, Bias: 3.000000, T: 24700, Avg. loss: 0.093962\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 248\n",
        "Norm: 5.88, NNZs: 2, Bias: 3.000000, T: 24800, Avg. loss: 0.093866\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 249\n",
        "Norm: 4.83, NNZs: 2, Bias: 5.000000, T: 24900, Avg. loss: 0.093674\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 250\n",
        "Norm: 6.71, NNZs: 2, Bias: 4.000000, T: 25000, Avg. loss: 0.093727\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 251\n",
        "Norm: 6.69, NNZs: 2, Bias: 5.000000, T: 25100, Avg. loss: 0.093703\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 252\n",
        "Norm: 8.65, NNZs: 2, Bias: 3.000000, T: 25200, Avg. loss: 0.093662\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 253\n",
        "Norm: 7.73, NNZs: 2, Bias: 4.000000, T: 25300, Avg. loss: 0.093855\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 254\n",
        "Norm: 7.66, NNZs: 2, Bias: 4.000000, T: 25400, Avg. loss: 0.093896\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 255\n",
        "Norm: 7.57, NNZs: 2, Bias: 5.000000, T: 25500, Avg. loss: 0.093867\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 256\n",
        "Norm: 8.12, NNZs: 2, Bias: 4.000000, T: 25600, Avg. loss: 0.093836\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 257\n",
        "Norm: 7.48, NNZs: 2, Bias: 5.000000, T: 25700, Avg. loss: 0.093790\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 258\n",
        "Norm: 8.12, NNZs: 2, Bias: 4.000000, T: 25800, Avg. loss: 0.094001\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 259\n",
        "Norm: 7.63, NNZs: 2, Bias: 5.000000, T: 25900, Avg. loss: 0.094022\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 260\n",
        "Norm: 7.23, NNZs: 2, Bias: 5.000000, T: 26000, Avg. loss: 0.094063\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 261\n",
        "Norm: 7.83, NNZs: 2, Bias: 6.000000, T: 26100, Avg. loss: 0.094010\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 262\n",
        "Norm: 8.16, NNZs: 2, Bias: 4.000000, T: 26200, Avg. loss: 0.094190\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 263\n",
        "Norm: 7.81, NNZs: 2, Bias: 5.000000, T: 26300, Avg. loss: 0.094100\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 264\n",
        "Norm: 7.06, NNZs: 2, Bias: 5.000000, T: 26400, Avg. loss: 0.094126\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 265\n",
        "Norm: 7.48, NNZs: 2, Bias: 4.000000, T: 26500, Avg. loss: 0.094052\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 266\n",
        "Norm: 7.58, NNZs: 2, Bias: 3.000000, T: 26600, Avg. loss: 0.094004\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 267\n",
        "Norm: 7.84, NNZs: 2, Bias: 2.000000, T: 26700, Avg. loss: 0.094138\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 268\n",
        "Norm: 7.34, NNZs: 2, Bias: 3.000000, T: 26800, Avg. loss: 0.094066\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 269\n",
        "Norm: 6.37, NNZs: 2, Bias: 4.000000, T: 26900, Avg. loss: 0.094214\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 270\n",
        "Norm: 5.49, NNZs: 2, Bias: 4.000000, T: 27000, Avg. loss: 0.094227\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 271\n",
        "Norm: 4.90, NNZs: 2, Bias: 4.000000, T: 27100, Avg. loss: 0.094062\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 272\n",
        "Norm: 5.91, NNZs: 2, Bias: 4.000000, T: 27200, Avg. loss: 0.093955\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 273\n",
        "Norm: 6.81, NNZs: 2, Bias: 3.000000, T: 27300, Avg. loss: 0.093909\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 274\n",
        "Norm: 6.66, NNZs: 2, Bias: 3.000000, T: 27400, Avg. loss: 0.093863\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 275\n",
        "Norm: 6.12, NNZs: 2, Bias: 3.000000, T: 27500, Avg. loss: 0.094051\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 276\n",
        "Norm: 6.19, NNZs: 2, Bias: 4.000000, T: 27600, Avg. loss: 0.094073\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 277\n",
        "Norm: 7.04, NNZs: 2, Bias: 2.000000, T: 27700, Avg. loss: 0.093906\n",
        "Total training time: 0.02 seconds.\n",
        "-- Epoch 278\n",
        "Norm: 5.76, NNZs: 2, Bias: 4.000000, T: 27800, Avg. loss: 0.093985\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 279\n",
        "Norm: 5.82, NNZs: 2, Bias: 3.000000, T: 27900, Avg. loss: 0.093956\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 280\n",
        "Norm: 5.67, NNZs: 2, Bias: 3.000000, T: 28000, Avg. loss: 0.093797\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 281\n",
        "Norm: 5.61, NNZs: 2, Bias: 4.000000, T: 28100, Avg. loss: 0.093818\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 282\n",
        "Norm: 7.69, NNZs: 2, Bias: 3.000000, T: 28200, Avg. loss: 0.093738\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 283\n",
        "Norm: 7.29, NNZs: 2, Bias: 4.000000, T: 28300, Avg. loss: 0.093684\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 284\n",
        "Norm: 6.45, NNZs: 2, Bias: 4.000000, T: 28400, Avg. loss: 0.093716\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 285\n",
        "Norm: 7.16, NNZs: 2, Bias: 4.000000, T: 28500, Avg. loss: 0.093702\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 286\n",
        "Norm: 6.77, NNZs: 2, Bias: 4.000000, T: 28600, Avg. loss: 0.093875\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 287\n",
        "Norm: 7.18, NNZs: 2, Bias: 4.000000, T: 28700, Avg. loss: 0.093867\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 288\n",
        "Norm: 7.17, NNZs: 2, Bias: 5.000000, T: 28800, Avg. loss: 0.093838\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 289\n",
        "Norm: 7.67, NNZs: 2, Bias: 4.000000, T: 28900, Avg. loss: 0.093801\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 290\n",
        "Norm: 7.16, NNZs: 2, Bias: 4.000000, T: 29000, Avg. loss: 0.093764\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 291\n",
        "Norm: 7.90, NNZs: 2, Bias: 4.000000, T: 29100, Avg. loss: 0.093765\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 292\n",
        "Norm: 7.36, NNZs: 2, Bias: 5.000000, T: 29200, Avg. loss: 0.093758\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 293\n",
        "Norm: 7.46, NNZs: 2, Bias: 4.000000, T: 29300, Avg. loss: 0.093779\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 294\n",
        "Norm: 6.67, NNZs: 2, Bias: 5.000000, T: 29400, Avg. loss: 0.093839\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 295\n",
        "Norm: 6.87, NNZs: 2, Bias: 4.000000, T: 29500, Avg. loss: 0.093832\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 296\n",
        "Norm: 6.26, NNZs: 2, Bias: 4.000000, T: 29600, Avg. loss: 0.093715\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 297\n",
        "Norm: 6.24, NNZs: 2, Bias: 4.000000, T: 29700, Avg. loss: 0.093803\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 298\n",
        "Norm: 7.44, NNZs: 2, Bias: 3.000000, T: 29800, Avg. loss: 0.093840\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 299\n",
        "Norm: 6.27, NNZs: 2, Bias: 5.000000, T: 29900, Avg. loss: 0.093849\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 300\n",
        "Norm: 6.09, NNZs: 2, Bias: 4.000000, T: 30000, Avg. loss: 0.093927\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 301\n",
        "Norm: 6.85, NNZs: 2, Bias: 3.000000, T: 30100, Avg. loss: 0.093971\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 302\n",
        "Norm: 5.96, NNZs: 2, Bias: 3.000000, T: 30200, Avg. loss: 0.093998\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 303\n",
        "Norm: 6.99, NNZs: 2, Bias: 3.000000, T: 30300, Avg. loss: 0.094036\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 304\n",
        "Norm: 6.35, NNZs: 2, Bias: 4.000000, T: 30400, Avg. loss: 0.094035\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 305\n",
        "Norm: 6.16, NNZs: 2, Bias: 3.000000, T: 30500, Avg. loss: 0.094056\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 306\n",
        "Norm: 6.06, NNZs: 2, Bias: 3.000000, T: 30600, Avg. loss: 0.094156\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 307\n",
        "Norm: 5.77, NNZs: 2, Bias: 3.000000, T: 30700, Avg. loss: 0.094063\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 308\n",
        "Norm: 5.11, NNZs: 2, Bias: 4.000000, T: 30800, Avg. loss: 0.094046\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 309\n",
        "Norm: 6.01, NNZs: 2, Bias: 2.000000, T: 30900, Avg. loss: 0.093907\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 310\n",
        "Norm: 5.12, NNZs: 2, Bias: 3.000000, T: 31000, Avg. loss: 0.094014\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 311\n",
        "Norm: 5.70, NNZs: 2, Bias: 2.000000, T: 31100, Avg. loss: 0.093866\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 312\n",
        "Norm: 4.47, NNZs: 2, Bias: 3.000000, T: 31200, Avg. loss: 0.093780\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 313\n",
        "Norm: 5.01, NNZs: 2, Bias: 2.000000, T: 31300, Avg. loss: 0.093576\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 314\n",
        "Norm: 5.54, NNZs: 2, Bias: 2.000000, T: 31400, Avg. loss: 0.093523\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 315\n",
        "Norm: 6.11, NNZs: 2, Bias: 3.000000, T: 31500, Avg. loss: 0.093476\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 316\n",
        "Norm: 7.38, NNZs: 2, Bias: 3.000000, T: 31600, Avg. loss: 0.093414\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 317\n",
        "Norm: 7.18, NNZs: 2, Bias: 3.000000, T: 31700, Avg. loss: 0.093387\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 318\n",
        "Norm: 6.66, NNZs: 2, Bias: 3.000000, T: 31800, Avg. loss: 0.093349\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 319\n",
        "Norm: 6.87, NNZs: 2, Bias: 3.000000, T: 31900, Avg. loss: 0.093388\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 320\n",
        "Norm: 6.57, NNZs: 2, Bias: 4.000000, T: 32000, Avg. loss: 0.093362\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 321\n",
        "Norm: 7.06, NNZs: 2, Bias: 3.000000, T: 32100, Avg. loss: 0.093358\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 322\n",
        "Norm: 7.04, NNZs: 2, Bias: 3.000000, T: 32200, Avg. loss: 0.093421\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 323\n",
        "Norm: 6.12, NNZs: 2, Bias: 3.000000, T: 32300, Avg. loss: 0.093459\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 324\n",
        "Norm: 6.98, NNZs: 2, Bias: 3.000000, T: 32400, Avg. loss: 0.093490\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 325\n",
        "Norm: 7.83, NNZs: 2, Bias: 3.000000, T: 32500, Avg. loss: 0.093441\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 326\n",
        "Norm: 8.46, NNZs: 2, Bias: 3.000000, T: 32600, Avg. loss: 0.093474\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 327\n",
        "Norm: 7.91, NNZs: 2, Bias: 4.000000, T: 32700, Avg. loss: 0.093501\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 328\n",
        "Norm: 7.26, NNZs: 2, Bias: 6.000000, T: 32800, Avg. loss: 0.093497\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 329\n",
        "Norm: 7.20, NNZs: 2, Bias: 5.000000, T: 32900, Avg. loss: 0.093589\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 330\n",
        "Norm: 7.58, NNZs: 2, Bias: 4.000000, T: 33000, Avg. loss: 0.093470\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 331\n",
        "Norm: 7.55, NNZs: 2, Bias: 4.000000, T: 33100, Avg. loss: 0.093553\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 332\n",
        "Norm: 7.81, NNZs: 2, Bias: 4.000000, T: 33200, Avg. loss: 0.093561\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 333\n",
        "Norm: 6.85, NNZs: 2, Bias: 5.000000, T: 33300, Avg. loss: 0.093665\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 334\n",
        "Norm: 7.60, NNZs: 2, Bias: 4.000000, T: 33400, Avg. loss: 0.093524\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 335\n",
        "Norm: 6.90, NNZs: 2, Bias: 5.000000, T: 33500, Avg. loss: 0.093575\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 336\n",
        "Norm: 7.41, NNZs: 2, Bias: 3.000000, T: 33600, Avg. loss: 0.093625\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 337\n",
        "Norm: 7.46, NNZs: 2, Bias: 4.000000, T: 33700, Avg. loss: 0.093697\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 338\n",
        "Norm: 7.54, NNZs: 2, Bias: 3.000000, T: 33800, Avg. loss: 0.093665\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 339\n",
        "Norm: 7.26, NNZs: 2, Bias: 4.000000, T: 33900, Avg. loss: 0.093810\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 340\n",
        "Norm: 6.90, NNZs: 2, Bias: 4.000000, T: 34000, Avg. loss: 0.093830\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 341\n",
        "Norm: 7.75, NNZs: 2, Bias: 4.000000, T: 34100, Avg. loss: 0.093809\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 342\n",
        "Norm: 8.17, NNZs: 2, Bias: 3.000000, T: 34200, Avg. loss: 0.093905\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 343\n",
        "Norm: 7.05, NNZs: 2, Bias: 5.000000, T: 34300, Avg. loss: 0.093876\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 344\n",
        "Norm: 6.78, NNZs: 2, Bias: 4.000000, T: 34400, Avg. loss: 0.093945\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 345\n",
        "Norm: 7.35, NNZs: 2, Bias: 4.000000, T: 34500, Avg. loss: 0.093971\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 346\n",
        "Norm: 7.15, NNZs: 2, Bias: 3.000000, T: 34600, Avg. loss: 0.093999\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 347\n",
        "Norm: 7.19, NNZs: 2, Bias: 4.000000, T: 34700, Avg. loss: 0.093993\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 348\n",
        "Norm: 7.35, NNZs: 2, Bias: 5.000000, T: 34800, Avg. loss: 0.093969\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 349\n",
        "Norm: 7.71, NNZs: 2, Bias: 5.000000, T: 34900, Avg. loss: 0.094018\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 350\n",
        "Norm: 7.64, NNZs: 2, Bias: 4.000000, T: 35000, Avg. loss: 0.094066\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 351\n",
        "Norm: 7.30, NNZs: 2, Bias: 5.000000, T: 35100, Avg. loss: 0.093980\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 352\n",
        "Norm: 7.94, NNZs: 2, Bias: 4.000000, T: 35200, Avg. loss: 0.094139\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 353\n",
        "Norm: 7.45, NNZs: 2, Bias: 5.000000, T: 35300, Avg. loss: 0.094150\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 354\n",
        "Norm: 7.04, NNZs: 2, Bias: 5.000000, T: 35400, Avg. loss: 0.094180\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 355\n",
        "Norm: 7.40, NNZs: 2, Bias: 5.000000, T: 35500, Avg. loss: 0.094127\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 356\n",
        "Norm: 7.97, NNZs: 2, Bias: 5.000000, T: 35600, Avg. loss: 0.094175\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 357\n",
        "Norm: 9.06, NNZs: 2, Bias: 4.000000, T: 35700, Avg. loss: 0.094101\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 358\n",
        "Norm: 7.58, NNZs: 2, Bias: 6.000000, T: 35800, Avg. loss: 0.094055\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 359\n",
        "Norm: 8.72, NNZs: 2, Bias: 5.000000, T: 35900, Avg. loss: 0.094068\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 360\n",
        "Norm: 8.80, NNZs: 2, Bias: 4.000000, T: 36000, Avg. loss: 0.094063\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 361\n",
        "Norm: 9.08, NNZs: 2, Bias: 3.000000, T: 36100, Avg. loss: 0.094176\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 362\n",
        "Norm: 9.01, NNZs: 2, Bias: 4.000000, T: 36200, Avg. loss: 0.094186\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 363\n",
        "Norm: 8.12, NNZs: 2, Bias: 5.000000, T: 36300, Avg. loss: 0.094295\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 364\n",
        "Norm: 7.92, NNZs: 2, Bias: 4.000000, T: 36400, Avg. loss: 0.094363\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 365\n",
        "Norm: 6.77, NNZs: 2, Bias: 5.000000, T: 36500, Avg. loss: 0.094495\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 366\n",
        "Norm: 6.11, NNZs: 2, Bias: 6.000000, T: 36600, Avg. loss: 0.094437\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 367\n",
        "Norm: 9.49, NNZs: 2, Bias: 4.000000, T: 36700, Avg. loss: 0.094287\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 368\n",
        "Norm: 9.09, NNZs: 2, Bias: 4.000000, T: 36800, Avg. loss: 0.094448\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 369\n",
        "Norm: 7.88, NNZs: 2, Bias: 5.000000, T: 36900, Avg. loss: 0.094628\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 370\n",
        "Norm: 6.91, NNZs: 2, Bias: 6.000000, T: 37000, Avg. loss: 0.094695\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 371\n",
        "Norm: 8.49, NNZs: 2, Bias: 4.000000, T: 37100, Avg. loss: 0.094594\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 372\n",
        "Norm: 8.44, NNZs: 2, Bias: 5.000000, T: 37200, Avg. loss: 0.094579\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 373\n",
        "Norm: 8.34, NNZs: 2, Bias: 4.000000, T: 37300, Avg. loss: 0.094613\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 374\n",
        "Norm: 7.26, NNZs: 2, Bias: 5.000000, T: 37400, Avg. loss: 0.094548\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 375\n",
        "Norm: 7.50, NNZs: 2, Bias: 4.000000, T: 37500, Avg. loss: 0.094455\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 376\n",
        "Norm: 8.24, NNZs: 2, Bias: 4.000000, T: 37600, Avg. loss: 0.094444\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 377\n",
        "Norm: 8.01, NNZs: 2, Bias: 4.000000, T: 37700, Avg. loss: 0.094363\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 378\n",
        "Norm: 7.75, NNZs: 2, Bias: 4.000000, T: 37800, Avg. loss: 0.094480\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 379\n",
        "Norm: 8.12, NNZs: 2, Bias: 3.000000, T: 37900, Avg. loss: 0.094525\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 380\n",
        "Norm: 7.37, NNZs: 2, Bias: 3.000000, T: 38000, Avg. loss: 0.094546\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 381\n",
        "Norm: 7.28, NNZs: 2, Bias: 3.000000, T: 38100, Avg. loss: 0.094602\n",
        "Total training time: 0.03 seconds.\n",
        "-- Epoch 382\n",
        "Norm: 6.59, NNZs: 2, Bias: 4.000000, T: 38200, Avg. loss: 0.094657\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 383\n",
        "Norm: 6.40, NNZs: 2, Bias: 4.000000, T: 38300, Avg. loss: 0.094635\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 384\n",
        "Norm: 6.93, NNZs: 2, Bias: 4.000000, T: 38400, Avg. loss: 0.094654\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 385\n",
        "Norm: 5.83, NNZs: 2, Bias: 5.000000, T: 38500, Avg. loss: 0.094741\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 386\n",
        "Norm: 6.56, NNZs: 2, Bias: 5.000000, T: 38600, Avg. loss: 0.094674\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 387\n",
        "Norm: 7.38, NNZs: 2, Bias: 4.000000, T: 38700, Avg. loss: 0.094680\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 388\n",
        "Norm: 7.11, NNZs: 2, Bias: 4.000000, T: 38800, Avg. loss: 0.094786\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 389\n",
        "Norm: 6.93, NNZs: 2, Bias: 3.000000, T: 38900, Avg. loss: 0.094815\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 390\n",
        "Norm: 8.05, NNZs: 2, Bias: 4.000000, T: 39000, Avg. loss: 0.094686\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 391\n",
        "Norm: 6.79, NNZs: 2, Bias: 5.000000, T: 39100, Avg. loss: 0.094642\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 392\n",
        "Norm: 7.97, NNZs: 2, Bias: 3.000000, T: 39200, Avg. loss: 0.094676\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 393\n",
        "Norm: 6.54, NNZs: 2, Bias: 4.000000, T: 39300, Avg. loss: 0.094707\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 394\n",
        "Norm: 5.53, NNZs: 2, Bias: 5.000000, T: 39400, Avg. loss: 0.094768\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 395\n",
        "Norm: 6.99, NNZs: 2, Bias: 3.000000, T: 39500, Avg. loss: 0.094842\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 396\n",
        "Norm: 6.04, NNZs: 2, Bias: 3.000000, T: 39600, Avg. loss: 0.094871\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 397\n",
        "Norm: 7.11, NNZs: 2, Bias: 3.000000, T: 39700, Avg. loss: 0.094891\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 398\n",
        "Norm: 6.49, NNZs: 2, Bias: 4.000000, T: 39800, Avg. loss: 0.094885\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 399\n",
        "Norm: 6.41, NNZs: 2, Bias: 3.000000, T: 39900, Avg. loss: 0.094893\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 400\n",
        "Norm: 6.23, NNZs: 2, Bias: 3.000000, T: 40000, Avg. loss: 0.094920\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 401\n",
        "Norm: 7.15, NNZs: 2, Bias: 3.000000, T: 40100, Avg. loss: 0.094882\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 402\n",
        "Norm: 5.60, NNZs: 2, Bias: 4.000000, T: 40200, Avg. loss: 0.094899\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 403\n",
        "Norm: 7.02, NNZs: 2, Bias: 3.000000, T: 40300, Avg. loss: 0.094830\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 404\n",
        "Norm: 5.71, NNZs: 2, Bias: 4.000000, T: 40400, Avg. loss: 0.094810\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 405\n",
        "Norm: 6.14, NNZs: 2, Bias: 3.000000, T: 40500, Avg. loss: 0.094748\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 406\n",
        "Norm: 5.96, NNZs: 2, Bias: 4.000000, T: 40600, Avg. loss: 0.094688\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 407\n",
        "Norm: 6.55, NNZs: 2, Bias: 3.000000, T: 40700, Avg. loss: 0.094573\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 408\n",
        "Norm: 6.71, NNZs: 2, Bias: 3.000000, T: 40800, Avg. loss: 0.094614\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 409\n",
        "Norm: 7.41, NNZs: 2, Bias: 3.000000, T: 40900, Avg. loss: 0.094605\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 410\n",
        "Norm: 7.45, NNZs: 2, Bias: 4.000000, T: 41000, Avg. loss: 0.094570\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 411\n",
        "Norm: 8.11, NNZs: 2, Bias: 3.000000, T: 41100, Avg. loss: 0.094610\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 412\n",
        "Norm: 7.23, NNZs: 2, Bias: 3.000000, T: 41200, Avg. loss: 0.094652\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 413\n",
        "Norm: 6.86, NNZs: 2, Bias: 3.000000, T: 41300, Avg. loss: 0.094767\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 414\n",
        "Norm: 6.34, NNZs: 2, Bias: 3.000000, T: 41400, Avg. loss: 0.094714\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 415\n",
        "Norm: 8.27, NNZs: 2, Bias: 2.000000, T: 41500, Avg. loss: 0.094608\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 416\n",
        "Norm: 7.49, NNZs: 2, Bias: 3.000000, T: 41600, Avg. loss: 0.094674\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 417\n",
        "Norm: 6.23, NNZs: 2, Bias: 4.000000, T: 41700, Avg. loss: 0.094641\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 418\n",
        "Norm: 8.43, NNZs: 2, Bias: 3.000000, T: 41800, Avg. loss: 0.094568\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 419\n",
        "Norm: 7.75, NNZs: 2, Bias: 4.000000, T: 41900, Avg. loss: 0.094635\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 420\n",
        "Norm: 6.95, NNZs: 2, Bias: 4.000000, T: 42000, Avg. loss: 0.094656\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 421\n",
        "Norm: 7.56, NNZs: 2, Bias: 4.000000, T: 42100, Avg. loss: 0.094675\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 422\n",
        "Norm: 7.17, NNZs: 2, Bias: 6.000000, T: 42200, Avg. loss: 0.094581\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 423\n",
        "Norm: 7.80, NNZs: 2, Bias: 5.000000, T: 42300, Avg. loss: 0.094594\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 424\n",
        "Norm: 8.18, NNZs: 2, Bias: 4.000000, T: 42400, Avg. loss: 0.094503\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 425\n",
        "Norm: 7.26, NNZs: 2, Bias: 5.000000, T: 42500, Avg. loss: 0.094544\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 426\n",
        "Norm: 8.17, NNZs: 2, Bias: 4.000000, T: 42600, Avg. loss: 0.094555\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 427\n",
        "Norm: 7.20, NNZs: 2, Bias: 5.000000, T: 42700, Avg. loss: 0.094644\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 428\n",
        "Norm: 7.81, NNZs: 2, Bias: 4.000000, T: 42800, Avg. loss: 0.094715\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 429\n",
        "Norm: 6.32, NNZs: 2, Bias: 5.000000, T: 42900, Avg. loss: 0.094724\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 430\n",
        "Norm: 6.73, NNZs: 2, Bias: 4.000000, T: 43000, Avg. loss: 0.094791\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 431\n",
        "Norm: 6.62, NNZs: 2, Bias: 3.000000, T: 43100, Avg. loss: 0.094795\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 432\n",
        "Norm: 6.63, NNZs: 2, Bias: 3.000000, T: 43200, Avg. loss: 0.094792\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 433\n",
        "Norm: 5.93, NNZs: 2, Bias: 4.000000, T: 43300, Avg. loss: 0.094831\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 434\n",
        "Norm: 6.05, NNZs: 2, Bias: 3.000000, T: 43400, Avg. loss: 0.094823\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 435\n",
        "Norm: 5.53, NNZs: 2, Bias: 3.000000, T: 43500, Avg. loss: 0.094762\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 436\n",
        "Norm: 5.78, NNZs: 2, Bias: 3.000000, T: 43600, Avg. loss: 0.094723\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 437\n",
        "Norm: 6.52, NNZs: 2, Bias: 5.000000, T: 43700, Avg. loss: 0.094656\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 438\n",
        "Norm: 6.06, NNZs: 2, Bias: 4.000000, T: 43800, Avg. loss: 0.094732\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 439\n",
        "Norm: 7.32, NNZs: 2, Bias: 4.000000, T: 43900, Avg. loss: 0.094738\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 440\n",
        "Norm: 7.07, NNZs: 2, Bias: 4.000000, T: 44000, Avg. loss: 0.094679\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 441\n",
        "Norm: 6.49, NNZs: 2, Bias: 5.000000, T: 44100, Avg. loss: 0.094680\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 442\n",
        "Norm: 7.58, NNZs: 2, Bias: 3.000000, T: 44200, Avg. loss: 0.094562\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 443\n",
        "Norm: 6.89, NNZs: 2, Bias: 4.000000, T: 44300, Avg. loss: 0.094576\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 444\n",
        "Norm: 6.83, NNZs: 2, Bias: 4.000000, T: 44400, Avg. loss: 0.094594\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 445\n",
        "Norm: 6.96, NNZs: 2, Bias: 3.000000, T: 44500, Avg. loss: 0.094512\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 446\n",
        "Norm: 6.44, NNZs: 2, Bias: 3.000000, T: 44600, Avg. loss: 0.094465\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 447\n",
        "Norm: 5.92, NNZs: 2, Bias: 4.000000, T: 44700, Avg. loss: 0.094483\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 448\n",
        "Norm: 5.21, NNZs: 2, Bias: 4.000000, T: 44800, Avg. loss: 0.094456\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 449\n",
        "Norm: 6.47, NNZs: 2, Bias: 3.000000, T: 44900, Avg. loss: 0.094377\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 450\n",
        "Norm: 5.39, NNZs: 2, Bias: 4.000000, T: 45000, Avg. loss: 0.094301\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 451\n",
        "Norm: 5.78, NNZs: 2, Bias: 3.000000, T: 45100, Avg. loss: 0.094205\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 452\n",
        "Norm: 5.16, NNZs: 2, Bias: 4.000000, T: 45200, Avg. loss: 0.094232\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 453\n",
        "Norm: 6.86, NNZs: 2, Bias: 3.000000, T: 45300, Avg. loss: 0.094188\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 454\n",
        "Norm: 6.34, NNZs: 2, Bias: 3.000000, T: 45400, Avg. loss: 0.094141\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 455\n",
        "Norm: 7.65, NNZs: 2, Bias: 2.000000, T: 45500, Avg. loss: 0.094147\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 456\n",
        "Norm: 7.14, NNZs: 2, Bias: 3.000000, T: 45600, Avg. loss: 0.094104\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 457\n",
        "Norm: 6.54, NNZs: 2, Bias: 4.000000, T: 45700, Avg. loss: 0.094141\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 458\n",
        "Norm: 5.66, NNZs: 2, Bias: 4.000000, T: 45800, Avg. loss: 0.094151\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 459\n",
        "Norm: 5.07, NNZs: 2, Bias: 4.000000, T: 45900, Avg. loss: 0.094056\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 460\n",
        "Norm: 6.06, NNZs: 2, Bias: 4.000000, T: 46000, Avg. loss: 0.093993\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 461\n",
        "Norm: 6.98, NNZs: 2, Bias: 3.000000, T: 46100, Avg. loss: 0.093959\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 462\n",
        "Norm: 6.83, NNZs: 2, Bias: 3.000000, T: 46200, Avg. loss: 0.093932\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 463\n",
        "Norm: 6.29, NNZs: 2, Bias: 3.000000, T: 46300, Avg. loss: 0.094046\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 464\n",
        "Norm: 6.36, NNZs: 2, Bias: 4.000000, T: 46400, Avg. loss: 0.094058\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 465\n",
        "Norm: 7.21, NNZs: 2, Bias: 2.000000, T: 46500, Avg. loss: 0.093956\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 466\n",
        "Norm: 5.93, NNZs: 2, Bias: 4.000000, T: 46600, Avg. loss: 0.094008\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 467\n",
        "Norm: 6.00, NNZs: 2, Bias: 3.000000, T: 46700, Avg. loss: 0.093989\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 468\n",
        "Norm: 5.84, NNZs: 2, Bias: 3.000000, T: 46800, Avg. loss: 0.093895\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 469\n",
        "Norm: 5.78, NNZs: 2, Bias: 4.000000, T: 46900, Avg. loss: 0.093908\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 470\n",
        "Norm: 7.87, NNZs: 2, Bias: 3.000000, T: 47000, Avg. loss: 0.093852\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 471\n",
        "Norm: 7.46, NNZs: 2, Bias: 4.000000, T: 47100, Avg. loss: 0.093822\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 472\n",
        "Norm: 6.63, NNZs: 2, Bias: 4.000000, T: 47200, Avg. loss: 0.093842\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 473\n",
        "Norm: 7.34, NNZs: 2, Bias: 4.000000, T: 47300, Avg. loss: 0.093831\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 474\n",
        "Norm: 6.95, NNZs: 2, Bias: 4.000000, T: 47400, Avg. loss: 0.093937\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 475\n",
        "Norm: 7.35, NNZs: 2, Bias: 4.000000, T: 47500, Avg. loss: 0.093931\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 476\n",
        "Norm: 7.33, NNZs: 2, Bias: 5.000000, T: 47600, Avg. loss: 0.093915\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 477\n",
        "Norm: 7.85, NNZs: 2, Bias: 4.000000, T: 47700, Avg. loss: 0.093888\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 478\n",
        "Norm: 7.33, NNZs: 2, Bias: 4.000000, T: 47800, Avg. loss: 0.093868\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 479\n",
        "Norm: 8.07, NNZs: 2, Bias: 4.000000, T: 47900, Avg. loss: 0.093865\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 480\n",
        "Norm: 7.52, NNZs: 2, Bias: 5.000000, T: 48000, Avg. loss: 0.093865\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 481\n",
        "Norm: 7.64, NNZs: 2, Bias: 4.000000, T: 48100, Avg. loss: 0.093875\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 482\n",
        "Norm: 6.84, NNZs: 2, Bias: 5.000000, T: 48200, Avg. loss: 0.093915\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 483\n",
        "Norm: 7.05, NNZs: 2, Bias: 4.000000, T: 48300, Avg. loss: 0.093909\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 484\n",
        "Norm: 6.44, NNZs: 2, Bias: 4.000000, T: 48400, Avg. loss: 0.093839\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 485\n",
        "Norm: 6.41, NNZs: 2, Bias: 4.000000, T: 48500, Avg. loss: 0.093893\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 486\n",
        "Norm: 7.61, NNZs: 2, Bias: 3.000000, T: 48600, Avg. loss: 0.093912\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 487\n",
        "Norm: 6.42, NNZs: 2, Bias: 5.000000, T: 48700, Avg. loss: 0.093924\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 488\n",
        "Norm: 6.26, NNZs: 2, Bias: 4.000000, T: 48800, Avg. loss: 0.093969\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 489\n",
        "Norm: 7.02, NNZs: 2, Bias: 3.000000, T: 48900, Avg. loss: 0.093995\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 490\n",
        "Norm: 6.14, NNZs: 2, Bias: 3.000000, T: 49000, Avg. loss: 0.094013\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 491\n",
        "Norm: 7.16, NNZs: 2, Bias: 3.000000, T: 49100, Avg. loss: 0.094034\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 492\n",
        "Norm: 6.52, NNZs: 2, Bias: 4.000000, T: 49200, Avg. loss: 0.094036\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 493\n",
        "Norm: 6.33, NNZs: 2, Bias: 3.000000, T: 49300, Avg. loss: 0.094049\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 494\n",
        "Norm: 6.23, NNZs: 2, Bias: 3.000000, T: 49400, Avg. loss: 0.094111\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 495\n",
        "Norm: 5.95, NNZs: 2, Bias: 3.000000, T: 49500, Avg. loss: 0.094054\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 496\n",
        "Norm: 5.28, NNZs: 2, Bias: 4.000000, T: 49600, Avg. loss: 0.094046\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 497\n",
        "Norm: 5.46, NNZs: 2, Bias: 3.000000, T: 49700, Avg. loss: 0.093973\n",
        "Total training time: 0.04 seconds.\n",
        "-- Epoch 498\n",
        "Norm: 5.80, NNZs: 2, Bias: 3.000000, T: 49800, Avg. loss: 0.094027\n",
        "Total training time: 0.05 seconds.\n",
        "-- Epoch 499\n",
        "Norm: 6.49, NNZs: 2, Bias: 3.000000, T: 49900, Avg. loss: 0.093944\n",
        "Total training time: 0.05 seconds.\n",
        "-- Epoch 500\n",
        "Norm: 6.31, NNZs: 2, Bias: 4.000000, T: 50000, Avg. loss: 0.093898\n",
        "Total training time: 0.05 seconds.\n"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y[y==1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 101,
       "text": [
        "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1])"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y[y==0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0])"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}